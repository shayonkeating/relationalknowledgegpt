{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63763dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reqs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import re\n",
    "import subprocess\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fab9fc43-6734-4cfc-893d-719cdbc879fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect the video files\n",
    "video_files = './video_files'\n",
    "audio_files = './audio_files'\n",
    "text_files = './text_files'\n",
    "\n",
    "folders = [video_files, audio_files, text_files]\n",
    "for folder in folders:\n",
    "    # Check if the output folder exists\n",
    "    if not os.path.exists(folder):\n",
    "    # If not, create the folder\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caf65782-c300-494e-ac2c-0f061baccc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the audio from the video and export the audio as a wav file\n",
    "for video_file in os.listdir(video_files):\n",
    "    if video_file.endswith('.mp4'):\n",
    "        video_path = os.path.join(video_files, video_file)\n",
    "        audio = AudioSegment.from_file(video_path, format=\"mp4\")\n",
    "        audio.export(os.path.join(audio_files, f\"{video_file[:-4]}.wav\"), format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "819292a0-7cc6-443c-bae2-38d3c7c704bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [02:37<00:00, 9.71MiB/s]\n",
      "/Users/shayonkeating/anaconda3/envs/pydata/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text for parkinsons_disease.wav has been saved to: ./text_files/parkinsons_disease.txt\n"
     ]
    }
   ],
   "source": [
    "# function to transcribe and save the output in txt file\n",
    "def transcribe_and_save(audio_files, text_files, model='medium.en'):\n",
    "    # Construct the Whisper command\n",
    "    whisper_command = f\"whisper '{audio_files}' --model {model}\"\n",
    "    \n",
    "    try:\n",
    "        # Run the Whisper command\n",
    "        transcription = subprocess.check_output(whisper_command, shell=True, text=True, stderr=subprocess.STDOUT)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during transcription: {e.output}\")\n",
    "        return\n",
    "    \n",
    "    # Clean and join the sentences\n",
    "    output_without_time = re.sub(r'\\[\\d+:\\d+\\.\\d+ --> \\d+:\\d+\\.\\d+\\]  ', '', transcription)\n",
    "    sentences = [line.strip() for line in output_without_time.split('\\n') if line.strip()]\n",
    "    joined_text = ' '.join(sentences)\n",
    "\n",
    "    # Create the corresponding text file name\n",
    "    audio_file_name = os.path.basename(audio_files)\n",
    "    text_file_name = os.path.splitext(audio_file_name)[0] + '.txt'\n",
    "    file_path = os.path.join(text_files, text_file_name)\n",
    "\n",
    "    # Save the output as a txt file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(joined_text)\n",
    "\n",
    "    print(f'Text for {audio_file_name} has been saved to: {file_path}')\n",
    "\n",
    "\n",
    "# Transcribing all the audio files in the directory\n",
    "for audio_file in os.listdir(audio_files):\n",
    "    if audio_file.endswith('.wav'):\n",
    "        audio_files = os.path.join(audio_files, audio_file)\n",
    "        transcribe_and_save(audio_files, text_files)\n",
    "\n",
    "# This will take a while to trduge through, be patient, its a lot of data for a 5 min video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e3bbb3-453d-4a46-95c9-7d6e0d57c590",
   "metadata": {},
   "source": [
    "### Making the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ffa5060-5523-4188-b9b2-3b23fa73f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Constants API endpoint, API key, prompt text\n",
    "from utils import read_api_key\n",
    "API_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
    "api_key_file_path = './auth/api_key.txt'\n",
    "api_key = read_api_key(api_key_file_path)\n",
    "prompt_text = \"\"\"Based on the given prompt, identify and enumerate all possible connections, then compile a summary of updates. \n",
    "For each update involving a connection, format it as [ENTITY 1, CONNECTION, ENTITY 2]. This connection is directional, \n",
    "indicating the sequence is significant.\n",
    "Example:\n",
    "prompt: The Sun generates solar energy and is also responsible for Vitamin D production.\n",
    "updates:\n",
    "[[\"Sun\", \"generates\", \"solar energy\"], [\"Sun\", \"responsible for\", \"Vitamin D\"]]\n",
    "prompt: $prompt\n",
    "updates:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1a2e6ba-4200-4631-875a-f6f09b882118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Creation Function\n",
    "def create_graph(df, rel_labels):\n",
    "    G = nx.from_pandas_edgelist(df, \"source\", \"target\",\n",
    "                              edge_attr=True, create_using=nx.MultiDiGraph())\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)\n",
    "    nx.draw_networkx_edge_labels(\n",
    "        G,\n",
    "        pos,\n",
    "        edge_labels=rel_labels,\n",
    "        font_color='red'\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "# Data Preparation Function\n",
    "def preparing_data_for_graph(api_response):\n",
    "    if api_response is None:\n",
    "        print(\"API response is None. Exiting function.\")\n",
    "        return None, None \n",
    "        \n",
    "    response_text = api_response.text\n",
    "    entity_relation_lst = json.loads(json.loads(response_text)[\"choices\"][0][\"text\"])\n",
    "    entity_relation_lst = [x for x in entity_relation_lst if len(x) == 3]\n",
    "    source = [i[0] for i in entity_relation_lst]\n",
    "    target = [i[2] for i in entity_relation_lst]\n",
    "    relations = [i[1] for i in entity_relation_lst]\n",
    "\n",
    "    kg_df = pd.DataFrame({'source': source, 'target': target, 'edge': relations})\n",
    "    relation_labels = dict(zip(zip(kg_df.source, kg_df.target), kg_df.edge))\n",
    "    return kg_df,relation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb78aa3b-5f44-4f02-b16d-b2f094e735ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Call Function\n",
    "def call_gpt_api(api_key, prompt_text):\n",
    "    global API_ENDPOINT\n",
    "    try:\n",
    "        data = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"prompt\": prompt_text,\n",
    "            \"max_tokens\": 3000,\n",
    "            \"stop\": \"\\n\",\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "        headers = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \" + api_key}\n",
    "        r = requests.post(url=API_ENDPOINT, headers=headers, json=data)\n",
    "        response_data = r.json()  # Parse the response as JSON\n",
    "        print(\"Response content:\", response_data)\n",
    "        return response_data\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b447a3cb-13f4-4a4e-845b-e99bf894adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(text_file_path, api_key):\n",
    "    # Use text_file_path, not file_path\n",
    "    with open(text_file_path, 'r') as file:\n",
    "        kb_text = file.read()\n",
    "\n",
    "    # Assuming prompt_text and the rest of your workflow is defined elsewhere correctly\n",
    "    global prompt_text\n",
    "    prompt_text = prompt_text.replace(\"$prompt\", kb_text)\n",
    "\n",
    "    api_response = call_gpt_api(api_key, prompt_text)\n",
    "    df, rel_labels = preparing_data_for_graph(api_response)\n",
    "    create_graph(df, rel_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cb94b33-e81f-4984-9d5e-113467a4ba33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: name 'requests' is not defined\n",
      "API response is None. Exiting function.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m text_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./text_files/parkinsons_disease.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m api_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(text_file_path, api_key)\u001b[0m\n\u001b[1;32m     10\u001b[0m api_response \u001b[38;5;241m=\u001b[39m call_gpt_api(api_key, prompt_text)\n\u001b[1;32m     11\u001b[0m df, rel_labels \u001b[38;5;241m=\u001b[39m preparing_data_for_graph(api_response)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mcreate_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m, in \u001b[0;36mcreate_graph\u001b[0;34m(df, rel_labels)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_graph\u001b[39m(df, rel_labels):\n\u001b[0;32m----> 3\u001b[0m     G \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pandas_edgelist(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m                               edge_attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_using\u001b[38;5;241m=\u001b[39mnx\u001b[38;5;241m.\u001b[39mMultiDiGraph())\n\u001b[1;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m12\u001b[39m))\n\u001b[1;32m      7\u001b[0m     pos \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mspring_layout(G)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nx' is not defined"
     ]
    }
   ],
   "source": [
    "text_file_path = \"./text_files/parkinsons_disease.txt\"\n",
    "api_key = api_key\n",
    "main(text_file_path, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4866620-81e8-4d08-860e-cf68d13b95a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
